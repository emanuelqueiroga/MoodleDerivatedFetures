{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caminho ed onde se encontram os logs do moodle\n",
    "caminho = \"/home/manolo/Documentos/UDELAR/logs/fic/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inicial dos arquivos e tipo deles\n",
    "tipoArc = \"logs*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminhoFinal = caminho + tipoArc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manolo/Documentos/UDELAR/logs/fic/logs*.csv\n"
     ]
    }
   ],
   "source": [
    "print(caminhoFinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#enf\n",
    "if(nameArc == 'logs_Administración I 2018_20191015-1124.csv' \n",
    "   or nameArc == 'logs_Microbiología2-2018_20191015-1126.csv'\n",
    "   or nameArc == 'logs_Micro-AyA 2018-P93-CURE_20191015-1200.csv'):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#fic \n",
    "if(nameArc == 'logs_Teoría del cine_20191015-1206.csv' \n",
    "   or nameArc == 'logs_SocCom_20191015-1210.csv'):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#bio\n",
    "if(nameArc == 'logs_Biología Celular 2018_20191015-1711.csv' \n",
    "   or nameArc == 'logs_Biología Vegetal 2018_20191015-1715.csv'\n",
    "   or nameArc == 'logs_Química Orgánica I Química II 2018_20191015-1717.csv'\n",
    "   or nameArc == 'logs_Genética General 2018_20191015-1722.csv'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_SocCom_20191015-1210.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_TC_I_20191015-1215.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_TC_II_20191015-1234.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_Imagen I_20191015-1327.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_Comunicación Sonora_20191015-1237.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_Economía y Política_20191015-1222.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_Teoría del cine_20191015-1206.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_EstadísticaBásica_20191015-1247.csv\n"
     ]
    }
   ],
   "source": [
    "for f in glob.glob(caminhoFinal):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_SocCom_20191015-1210.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_TC_I_20191015-1215.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_TC_II_20191015-1234.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_Imagen I_20191015-1327.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_Comunicación Sonora_20191015-1237.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_Economía y Política_20191015-1222.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_Teoría del cine_20191015-1206.csv\n",
      "/home/manolo/Documentos/UDELAR/logs/fic/logs_EstadísticaBásica_20191015-1247.csv\n"
     ]
    }
   ],
   "source": [
    "for f in glob.glob(caminhoFinal):\n",
    "    print(f)\n",
    "    nameArc = f\n",
    "    #print(type(nameArc))\n",
    "    nameArc = nameArc.rsplit(\"/\", -1)\n",
    "    #print(nameArc[-1])\n",
    "    nameSave = \"Int\"+nameArc[-1]\n",
    "    save = caminho + \"TypeWeeks\" + nameSave\n",
    "    \n",
    "    logs = pd.read_csv(f)\n",
    "    \n",
    "    #retira primeira parte da string\n",
    "    logs['Time'] = logs['Time'].str.rsplit(\",\", 0).str[0]\n",
    "\n",
    "    logs['Time'] = logs['Time'].replace({'/' : '-'}, regex=True)\n",
    "    #retira primeira parte da string\n",
    "    logs['Description'] = logs['Description'].replace({'The user with id' : ''}, regex=True)\n",
    "    #Substitui as aspas\n",
    "    logs['Description'] = logs['Description'].replace({\"'\" : ''}, regex=True)\n",
    "    #substitui o espaço por -\n",
    "    logs['Description'] = logs['Description'].replace({\" \" : '-'}, regex=True)\n",
    "    #splita a string pelo -, passa o segundo elemento do vetor resultante para o df original\n",
    "    logs['Description'] = logs['Description'].str.rsplit(\"-\", 0).str[1]\n",
    "    \n",
    "    logs['datas'] =  pd.to_datetime(logs.Time, format='%d-%m-%y')\n",
    "    logs['datas'] = logs['datas'].dt.date\n",
    "    if(nameArc == 'logs_Teoría del cine_20191015-1206.csv' \n",
    "       or nameArc == 'logs_SocCom_20191015-1210.csv'):\n",
    "        cweek1 = (logs.datas >= pd.Timestamp(2018,8,15)) & (logs.datas < pd.Timestamp(2018,9,1))\n",
    "        week1 = logs.loc[cweek1, ]\n",
    "        cweek2 = (logs.datas >= pd.Timestamp(2018,9,1)) & (logs.datas < pd.Timestamp(2018,9,15))\n",
    "        week2 = logs.loc[cweek2, ]\n",
    "        cweek3 = (logs.datas >= pd.Timestamp(2018,9,15)) & (logs.datas < pd.Timestamp(2018,10,1))\n",
    "        week3 = logs.loc[cweek3, ]\n",
    "        cweek4 = (logs.datas >= pd.Timestamp(2018,10,1)) & (logs.datas < pd.Timestamp(2018,10,15))\n",
    "        week4 = logs.loc[cweek4, ]\n",
    "        cweek5 = (logs.datas >= pd.Timestamp(2018,10,15)) & (logs.datas < pd.Timestamp(2018,11,1))\n",
    "        week5 = logs.loc[cweek5, ]\n",
    "        cweek6 = (logs.datas >= pd.Timestamp(2018,11,1)) & (logs.datas < pd.Timestamp(2018,11,15))\n",
    "        week6 = logs.loc[cweek6, ]\n",
    "        cweek7 = (logs.datas >= pd.Timestamp(2018,11,15)) & (logs.datas < pd.Timestamp(2018,12,1))\n",
    "        week7 = logs.loc[cweek7, ]\n",
    "        cweek8 = (logs.datas >= pd.Timestamp(2018,12,1)) & (logs.datas < pd.Timestamp(2018,12,15))\n",
    "        week8 = logs.loc[cweek8, ]\n",
    "    else:\n",
    "        cweek1 = (logs.datas >= pd.Timestamp(2018,3,15)) & (logs.datas < pd.Timestamp(2018,4,1))\n",
    "        week1 = logs.loc[cweek1, ]\n",
    "        cweek2 = (logs.datas >= pd.Timestamp(2018,4,1)) & (logs.datas < pd.Timestamp(2018,4,15))\n",
    "        week2 = logs.loc[cweek2, ]\n",
    "        cweek3 = (logs.datas >= pd.Timestamp(2018,4,15)) & (logs.datas < pd.Timestamp(2018,5,1))\n",
    "        week3 = logs.loc[cweek3, ]\n",
    "        cweek4 = (logs.datas >= pd.Timestamp(2018,5,1)) & (logs.datas < pd.Timestamp(2018,5,15))\n",
    "        week4 = logs.loc[cweek4, ]\n",
    "        cweek5 = (logs.datas >= pd.Timestamp(2018,5,15)) & (logs.datas < pd.Timestamp(2018,6,1))\n",
    "        week5 = logs.loc[cweek5, ]\n",
    "        cweek6 = (logs.datas >= pd.Timestamp(2018,6,1)) & (logs.datas < pd.Timestamp(2018,6,15))\n",
    "        week6 = logs.loc[cweek6, ]\n",
    "        cweek7 = (logs.datas >= pd.Timestamp(2018,6,15)) & (logs.datas < pd.Timestamp(2018,7,1))\n",
    "        week7 = logs.loc[cweek7, ]\n",
    "        cweek8 = (logs.datas >= pd.Timestamp(2018,7,1)) & (logs.datas <= pd.Timestamp(2018,7,15))\n",
    "        week8 = logs.loc[cweek8, ]\n",
    "    \n",
    "        \n",
    "    contagem1 = week1.groupby(['Description', 'Component'])['Time'].count()\n",
    "    contagem2 = week2.groupby(['Description', 'Component'])['Time'].count()\n",
    "    contagem3 = week3.groupby(['Description', 'Component'])['Time'].count()\n",
    "    contagem4 = week4.groupby(['Description', 'Component'])['Time'].count()\n",
    "    contagem5 = week5.groupby(['Description', 'Component'])['Time'].count()\n",
    "    contagem6 = week6.groupby(['Description', 'Component'])['Time'].count()\n",
    "    contagem7 = week7.groupby(['Description', 'Component'])['Time'].count()\n",
    "    contagem8 = week8.groupby(['Description', 'Component'])['Time'].count()\n",
    "    \n",
    "    contagem1.rename(columns={'': 'count'}, inplace=True)\n",
    "    contagem2.rename(columns={'': 'count'}, inplace=True)\n",
    "    contagem3.rename(columns={'': 'count'}, inplace=True)\n",
    "    contagem4.rename(columns={'': 'count'}, inplace=True)\n",
    "    contagem5.rename(columns={'': 'count'}, inplace=True)\n",
    "    contagem6.rename(columns={'': 'count'}, inplace=True)\n",
    "    contagem7.rename(columns={'': 'count'}, inplace=True)\n",
    "    contagem8.rename(columns={'': 'count'}, inplace=True)\n",
    "    \n",
    "    result = pd.concat([contagem1, contagem2, contagem3, contagem4, contagem5,\n",
    "                    contagem6, contagem7, contagem8], axis=1, sort=False)\n",
    "    \n",
    "    #sult.to_csv('teste.csv', header=True)\n",
    "    \n",
    "    result.to_csv(save, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
